{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis of Global College Statistics\n",
    "\n",
    "This notebook performs comprehensive machine learning analysis on the Global College Statistics Dataset to predict placement rates and identify important factors affecting college performance.\n",
    "\n",
    "## Table of Contents:\n",
    "1. Data Loading and Preprocessing\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Engineering\n",
    "4. Model Training and Evaluation\n",
    "5. Advanced Model Tuning\n",
    "6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('College Data.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Distribution of target variable (Placement Rate)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Placement Rate'], kde=True)\n",
    "plt.title('Distribution of Placement Rates')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create new features\n",
    "df['Student_Faculty_Ratio'] = df['Total Students'] / df['Faculty Count']\n",
    "df['Female_Ratio'] = df['Female'] / df['Total Students']\n",
    "df['Research_Per_Faculty'] = df['Research Papers Published'] / df['Faculty Count']\n",
    "\n",
    "# Select features for modeling\n",
    "features = ['CGPA', 'Research Papers Published', 'Faculty Count', 'Total Students',\n",
    "           'Student_Faculty_Ratio', 'Female_Ratio', 'Research_Per_Faculty', 'Annual Family Income']\n",
    "target = 'Placement Rate'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_and_evaluate_model(model, name, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Train R2: {train_r2:.4f}\")\n",
    "    print(f\"Test R2: {test_r2:.4f}\")\n",
    "    print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    \n",
    "    return model, y_pred_test\n",
    "\n",
    "# Train different models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model, predictions = train_and_evaluate_model(model, name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    results[name] = {'model': model, 'predictions': predictions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tune the best performing model (assuming Random Forest)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_best)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance plot\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()\n",
    "\n",
    "# Actual vs Predicted plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Placement Rate')\n",
    "plt.ylabel('Predicted Placement Rate')\n",
    "plt.title('Actual vs Predicted Placement Rates')\n",
    "plt.show()\n",
    "\n",
    "# Model comparison plot\n",
    "model_scores = {\n",
    "    name: r2_score(y_test, results[name]['predictions'])\n",
    "    for name in results.keys()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(model_scores.keys()), y=list(model_scores.values()))\n",
    "plt.title('Model Comparison (RÂ² Score)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Insights\n",
    "\n",
    "1. Model Performance:\n",
    "   - Compare the performance of different models\n",
    "   - Identify the best performing model and its key parameters\n",
    "\n",
    "2. Feature Importance:\n",
    "   - List the most important features affecting placement rates\n",
    "   - Discuss the relationships between features\n",
    "\n",
    "3. Recommendations:\n",
    "   - Suggest ways to improve placement rates based on the model insights\n",
    "   - Identify areas for further investigation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
